{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0OSye6XY+mpWWsmz8D1N3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7SDLvMkkpvJ",
        "outputId": "3a564329-834a-45ff-ec7e-021af8d7a589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium\n",
        "import gymnasium as gym\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34a96410"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from IPython.display import display, clear_output\n",
        "import time\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Helper function for epsilon-greedy policy\n",
        "def choose_action(state, q_table, action_space, epsilon):\n",
        "    if np.random.uniform(0, 1) < epsilon:\n",
        "        return action_space.sample()  # Explore action space\n",
        "    else:\n",
        "        return np.argmax(q_table[state, :]) # Exploit learned values\n",
        "\n",
        "# Function to visualize the environment map\n",
        "def visualize_env_map(env, env_name, save_dir=\".\"):\n",
        "    \"\"\"\n",
        "    Visualizes the environment map and saves it as a PNG.\n",
        "    \"\"\"\n",
        "    if env_name == 'FrozenLake-v1':\n",
        "        # FrozenLake has a text-based rendering that can be captured\n",
        "        # We can try to render it and convert to an image\n",
        "        try:\n",
        "            # Attempt to get the text render\n",
        "            output = env.render()\n",
        "            if output:\n",
        "                print(f\"Map for {env_name}:\")\n",
        "                print(output)\n",
        "                # For visual map, we'll rely on creating a visual representation later\n",
        "                # or if render_mode='rgb_array' is supported and useful for a static map.\n",
        "                # Since FrozenLake text render is informative, displaying it for now.\n",
        "                pass\n",
        "            else:\n",
        "                 print(f\"Could not get text rendering for {env_name}.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error rendering {env_name} for map visualization: {e}\")\n",
        "\n",
        "    elif env_name == 'Taxi-v3':\n",
        "        # Taxi also has a text render\n",
        "        try:\n",
        "            output = env.render()\n",
        "            if output:\n",
        "                print(f\"Map for {env_name}:\")\n",
        "                print(output)\n",
        "                pass\n",
        "            else:\n",
        "                 print(f\"Could not get text rendering for {env_name}.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error rendering {env_name} for map visualization: {e}\")\n",
        "\n",
        "    elif env_name == 'CliffWalking-v0':\n",
        "         # CliffWalking has a text render\n",
        "        try:\n",
        "            output = env.render()\n",
        "            if output:\n",
        "                print(f\"Map for {env_name}:\")\n",
        "                print(output)\n",
        "                pass\n",
        "            else:\n",
        "                 print(f\"Could not get text rendering for {env_name}.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error rendering {env_name} for map visualization: {e}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Map visualization not specifically implemented for {env_name}. Displaying basic info:\")\n",
        "        print(f\"Observation Space: {env.observation_space}\")\n",
        "        print(f\"Action Space: {env.action_space}\")\n",
        "\n",
        "    # Note: Saving a generic visual map as PNG for all discrete environments\n",
        "    # requires more sophisticated rendering or creating a custom visualization\n",
        "    # based on environment structure, which can be complex and environment-specific.\n",
        "    # The text-based render is the most straightforward for these environments.\n",
        "    # If a visual PNG is strictly required, this function would need significant\n",
        "    # expansion or a different rendering approach. For now, focusing on the text map.\n",
        "\n",
        "# Function to generate and save video\n",
        "def create_video_from_frames(frame_folder, output_filename, fps=30):\n",
        "    images = [img for img in os.listdir(frame_folder) if img.endswith(\".png\")]\n",
        "    # Sort the frames by the numerical part of the filename\n",
        "    images.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
        "\n",
        "    if not images:\n",
        "        print(f\"No frames found in {frame_folder} to create video.\")\n",
        "        return\n",
        "\n",
        "    # Use the first image to determine dimensions\n",
        "    first_frame_path = os.path.join(frame_folder, images[0])\n",
        "    try:\n",
        "        frame = Image.open(first_frame_path)\n",
        "        width, height = frame.size\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error opening first frame: {first_frame_path}\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing first frame {first_frame_path}: {e}\")\n",
        "        return\n",
        "\n",
        "\n",
        "    import subprocess\n",
        "    output_path = os.path.join(\".\", output_filename) # Save in the current directory\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    output_dir = os.path.dirname(output_path)\n",
        "    if output_dir and not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Use ffmpeg to create the MP4 video\n",
        "    # -y: overwrite output file without asking\n",
        "    # -f image2: input format is image sequence\n",
        "    # -r {fps}: input frame rate\n",
        "    # -i {frame_folder}/frame_%04d.png: input file pattern (assuming frame_0000.png, frame_0001.png, ...)\n",
        "    # -vcodec libx264: video codec\n",
        "    # -crf 25: constant rate factor (quality, lower is better)\n",
        "    # -pix_fmt yuv420p: pixel format (for compatibility)\n",
        "    command = [\n",
        "        'ffmpeg', '-y', '-f', 'image2', '-r', str(fps),\n",
        "        '-i', os.path.join(frame_folder, 'frame_%04d.png'),\n",
        "        '-vcodec', 'libx264', '-crf', '25', '-pix_fmt', 'yuv420p',\n",
        "        output_path\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        subprocess.run(command, check=True, capture_output=True, text=True)\n",
        "        print(f\"Video successfully created: {output_path}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error creating video: {e}\")\n",
        "        print(f\"STDOUT: {e.stdout}\")\n",
        "        print(f\"STDERR: {e.stderr}\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"ffmpeg not found. Please install ffmpeg to create videos.\")\n",
        "        print(\"You can install it in Colab using: !apt-get update && apt-get install ffmpeg\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during video creation: {e}\")\n",
        "\n",
        "\n",
        "# Function to clean up frame images\n",
        "def cleanup_frames(frame_folder):\n",
        "    for img in os.listdir(frame_folder):\n",
        "        if img.endswith(\".png\"):\n",
        "            try:\n",
        "                os.remove(os.path.join(frame_folder, img))\n",
        "            except OSError as e:\n",
        "                print(f\"Error removing frame {img}: {e}\")\n",
        "    if os.path.exists(frame_folder) and not os.listdir(frame_folder):\n",
        "         try:\n",
        "             os.rmdir(frame_folder)\n",
        "             print(f\"Cleaned up frame folder: {frame_folder}\")\n",
        "         except OSError as e:\n",
        "             print(f\"Error removing frame folder {frame_folder}: {e}\")"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "355071d3"
      },
      "source": [
        "## Taxi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d4528d3",
        "outputId": "467f6e53-39bb-4318-9686-1d19de66aac3"
      },
      "source": [
        "# Create and visualize the Taxi environment\n",
        "env_name_taxi = 'Taxi-v3'\n",
        "env_taxi = gym.make(env_name_taxi, render_mode='ansi')\n",
        "visualize_env_map(env_taxi, env_name_taxi)\n",
        "\n",
        "# Define hyperparameters for Taxi (can be adjusted)\n",
        "alpha_taxi = 0.1\n",
        "gamma_taxi = 0.99\n",
        "epsilon_taxi = 0.1\n",
        "num_episodes_taxi = 50000 # Taxi might need more episodes\n",
        "\n",
        "# Initialize Q-tables for Taxi\n",
        "q_table_sarsa_taxi = np.zeros((env_taxi.observation_space.n, env_taxi.action_space.n))\n",
        "q_table_qlearning_taxi = np.zeros((env_taxi.observation_space.n, env_taxi.action_space.n))\n",
        "\n",
        "# SARSA Implementation for Taxi\n",
        "print(\"Training SARSA on Taxi...\")\n",
        "for i in range(num_episodes_taxi):\n",
        "    state, _ = env_taxi.reset()\n",
        "    action = choose_action(state, q_table_sarsa_taxi, env_taxi.action_space, epsilon_taxi)\n",
        "    done = False\n",
        "    while not done:\n",
        "        next_state, reward, terminated, truncated, _ = env_taxi.step(action)\n",
        "        done = terminated or truncated\n",
        "        next_action = choose_action(next_state, q_table_sarsa_taxi, env_taxi.action_space, epsilon_taxi)\n",
        "\n",
        "        # SARSA update\n",
        "        old_value = q_table_sarsa_taxi[state, action]\n",
        "        next_q = q_table_sarsa_taxi[next_state, next_action]\n",
        "        new_value = old_value + alpha_taxi * (reward + gamma_taxi * next_q - old_value)\n",
        "        q_table_sarsa_taxi[state, action] = new_value\n",
        "\n",
        "        state = next_state\n",
        "        action = next_action\n",
        "\n",
        "print(\"SARSA training finished.\")\n",
        "\n",
        "# Q-Learning Implementation for Taxi\n",
        "print(\"\\nTraining Q-Learning on Taxi...\")\n",
        "for i in range(num_episodes_taxi):\n",
        "    state, _ = env_taxi.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = choose_action(state, q_table_qlearning_taxi, env_taxi.action_space, epsilon_taxi)\n",
        "        next_state, reward, terminated, truncated, _ = env_taxi.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        # Q-Learning update\n",
        "        old_value = q_table_qlearning_taxi[state, action]\n",
        "        max_next_q = np.max(q_table_qlearning_taxi[next_state, :])\n",
        "        new_value = old_value + alpha_taxi * (reward + gamma_taxi * max_next_q - old_value)\n",
        "        q_table_qlearning_taxi[state, action] = new_value\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "print(\"Q-Learning training finished.\")\n",
        "\n",
        "env_taxi.close() # Close the environment after training"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error rendering Taxi-v3 for map visualization: Cannot call `env.render()` before calling `env.reset()`, if this is an intended action, set `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\n",
            "Training SARSA on Taxi...\n",
            "SARSA training finished.\n",
            "\n",
            "Training Q-Learning on Taxi...\n",
            "Q-Learning training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f311a797",
        "outputId": "cfe16e41-c3a4-4afa-a614-904af7ca0543"
      },
      "source": [
        "# Function to generate a successful episode path, specific to Taxi\n",
        "def generate_successful_episode_path_taxi(env_name, q_table, max_retries=1000, max_steps_per_episode=1000):\n",
        "    \"\"\"\n",
        "    Generates a successful episode path for Taxi environment using the learned Q-table and policy,\n",
        "    retrying until a successful episode (reaching the goal) is found\n",
        "    or max_retries is reached.\n",
        "    \"\"\"\n",
        "    env = gym.make(env_name, render_mode='rgb_array') # Use rgb_array for rendering frames\n",
        "    path = []\n",
        "    is_successful = False\n",
        "    attempt = 0\n",
        "\n",
        "    while attempt < max_retries and not is_successful:\n",
        "        state, _ = env.reset()\n",
        "        path = [state]\n",
        "        done = False\n",
        "        steps = 0\n",
        "        while not done and steps < max_steps_per_episode:\n",
        "            # Choose action based on greedy policy (exploit learned knowledge)\n",
        "            action = np.argmax(q_table[state, :])\n",
        "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "            done = terminated or truncated\n",
        "            path.append(next_state)\n",
        "            state = next_state\n",
        "            steps += 1\n",
        "\n",
        "            # Check if the goal state is reached successfully in Taxi\n",
        "            if env_name == 'Taxi-v3' and terminated and reward > 0:\n",
        "                 is_successful = True\n",
        "\n",
        "\n",
        "        attempt += 1\n",
        "\n",
        "    env.close()\n",
        "    if not is_successful:\n",
        "        print(f\"Warning: Could not find a successful episode for {env_name} after {max_retries} attempts.\")\n",
        "\n",
        "    return path, is_successful\n",
        "\n",
        "# Generate successful paths for Taxi (SARSA and Q-Learning)\n",
        "print(\"Generating successful episode paths for Taxi...\")\n",
        "\n",
        "taxi_sarsa_path, taxi_sarsa_success = generate_successful_episode_path_taxi('Taxi-v3', q_table_sarsa_taxi)\n",
        "print(f\"Taxi SARSA path generated. Success: {taxi_sarsa_success}\")\n",
        "\n",
        "taxi_qlearning_path, taxi_qlearning_success = generate_successful_episode_path_taxi('Taxi-v3', q_table_qlearning_taxi)\n",
        "print(f\"Taxi Q-Learning path generated. Success: {taxi_qlearning_success}\")\n",
        "\n",
        "print(\"Finished generating Taxi paths.\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating successful episode paths for Taxi...\n",
            "Taxi SARSA path generated. Success: True\n",
            "Taxi Q-Learning path generated. Success: True\n",
            "Finished generating Taxi paths.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e8f608a",
        "outputId": "e7c05530-c242-4698-cacc-63595c349e46"
      },
      "source": [
        "# Function to generate and save video\n",
        "def create_video_from_frames(frame_folder, output_filename, fps=30):\n",
        "    images = [img for img in os.listdir(frame_folder) if img.endswith(\".png\")]\n",
        "    # Sort the frames by the numerical part of the filename\n",
        "    images.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
        "\n",
        "    if not images:\n",
        "        print(f\"No frames found in {frame_folder} to create video.\")\n",
        "        return\n",
        "\n",
        "    # Use the first image to determine dimensions\n",
        "    first_frame_path = os.path.join(frame_folder, images[0])\n",
        "    try:\n",
        "        frame = Image.open(first_frame_path)\n",
        "        width, height = frame.size\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error opening first frame: {first_frame_path}\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing first frame {first_frame_path}: {e}\")\n",
        "        return\n",
        "\n",
        "    import subprocess\n",
        "    output_path = os.path.join(\".\", output_filename) # Save in the current directory\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    output_dir = os.path.dirname(output_path)\n",
        "    if output_dir and not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Use ffmpeg to create the MP4 video\n",
        "    # -y: overwrite output file without asking\n",
        "    # -f image2: input format is image sequence\n",
        "    # -r {fps}: input frame rate\n",
        "    # -i {frame_folder}/frame_%04d.png: input file pattern (assuming frame_0000.png, frame_0001.png, ...)\n",
        "    # -vcodec libx264: video codec\n",
        "    # -crf 25: constant rate factor (quality, lower is better)\n",
        "    # -pix_fmt yuv420p: pixel format (for compatibility)\n",
        "    command = [\n",
        "        'ffmpeg', '-y', '-f', 'image2', '-r', str(fps),\n",
        "        '-i', os.path.join(frame_folder, 'frame_%04d.png'),\n",
        "        '-vcodec', 'libx264', '-crf', '25', '-pix_fmt', 'yuv420p',\n",
        "        output_path\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        subprocess.run(command, check=True, capture_output=True, text=True)\n",
        "        print(f\"Video successfully created: {output_path}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error creating video: {e}\")\n",
        "        print(f\"STDOUT: {e.stdout}\")\n",
        "        print(f\"STDERR: {e.stderr}\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"ffmpeg not found. Please install ffmpeg to create videos.\")\n",
        "        print(\"You can install it in Colab using: !apt-get update && apt-get install ffmpeg\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during video creation: {e}\")\n",
        "\n",
        "\n",
        "# Function to clean up frame images (kept as is)\n",
        "def cleanup_frames(frame_folder):\n",
        "    for img in os.listdir(frame_folder):\n",
        "        if img.endswith(\".png\"):\n",
        "            try:\n",
        "                os.remove(os.path.join(frame_folder, img))\n",
        "            except OSError as e:\n",
        "                print(f\"Error removing frame {img}: {e}\")\n",
        "    if os.path.exists(frame_folder) and not os.listdir(frame_folder):\n",
        "         try:\n",
        "             os.rmdir(frame_folder)\n",
        "             print(f\"Cleaned up frame folder: {frame_folder}\")\n",
        "         except OSError as e:\n",
        "             print(f\"Error removing empty frame folder {frame_folder}: {e}\")\n",
        "\n",
        "\n",
        "# Function to generate video from learned policy, incorporating path generation, specific to Taxi\n",
        "def generate_video_from_learned_policy_and_path_taxi(env_name, q_table, output_filename, fps=2, max_retries=1000, max_steps_per_episode=1000, frame_folder=\"frames\"):\n",
        "    \"\"\"\n",
        "    Generates a successful episode for Taxi environment using the learned Q-table, renders frames,\n",
        "    creates an MP4 video, and cleans up frames.\n",
        "    Includes path generation within the function.\n",
        "    \"\"\"\n",
        "    # Ensure frame folder is clean before starting\n",
        "    if os.path.exists(frame_folder):\n",
        "        cleanup_frames(frame_folder)\n",
        "    else:\n",
        "        os.makedirs(frame_folder)\n",
        "\n",
        "    print(f\"Attempting to generate successful episode for {env_name} for video...\")\n",
        "    # Use the Taxi-specific path generation function\n",
        "    path, is_successful = generate_successful_episode_path_taxi(env_name, q_table, max_retries, max_steps_per_episode)\n",
        "\n",
        "    if not is_successful:\n",
        "        print(f\"Skipping video generation for {env_name} as no successful path was found after {max_retries} attempts.\")\n",
        "        return # Exit if no successful episode found\n",
        "\n",
        "    print(f\"Successful episode found for {env_name}. Generating video...\")\n",
        "\n",
        "    # Re-run the successful episode using the generated path and render frames\n",
        "    env = gym.make(env_name, render_mode='rgb_array')\n",
        "    state, _ = env.reset() # Start from the actual initial state\n",
        "    frames = []\n",
        "    frames.append(env.render()) # Render the initial state\n",
        "\n",
        "    # Step through the path and render\n",
        "    temp_env = gym.make(env_name, render_mode='rgb_array')\n",
        "    state, _ = temp_env.reset()\n",
        "    frames = []\n",
        "    frames.append(temp_env.render())\n",
        "    frame_count = 1\n",
        "    done = False\n",
        "    steps = 0\n",
        "    max_sim_steps = len(path) + 10 # Add a buffer\n",
        "\n",
        "    while not done and steps < max_steps_per_episode and steps < max_sim_steps:\n",
        "         action = np.argmax(q_table[state, :]) # Greedy action\n",
        "         next_state, reward, terminated, truncated, _ = temp_env.step(action)\n",
        "         done = terminated or truncated\n",
        "         frames.append(temp_env.render())\n",
        "         state = next_state\n",
        "         steps += 1\n",
        "\n",
        "         # Stop if the goal is reached successfully (Taxi specific check)\n",
        "         if terminated and reward > 0:\n",
        "             break\n",
        "\n",
        "\n",
        "    temp_env.close()\n",
        "\n",
        "    # Save frames if we have any\n",
        "    if frames:\n",
        "        for i, frame in enumerate(frames):\n",
        "            img = Image.fromarray(frame)\n",
        "            img.save(os.path.join(frame_folder, f\"frame_{i:04d}.png\"))\n",
        "    else:\n",
        "        print(f\"No frames were generated for {env_name}.\")\n",
        "        # Clean up the potentially created frame folder if no frames\n",
        "        if os.path.exists(frame_folder) and not os.listdir(frame_folder):\n",
        "             try:\n",
        "                 os.rmdir(frame_folder)\n",
        "             except OSError as e:\n",
        "                 print(f\"Error removing empty frame folder {frame_folder}: {e}\")\n",
        "        return\n",
        "\n",
        "\n",
        "    # Create video from saved frames\n",
        "    create_video_from_frames(frame_folder, output_filename, fps=fps)\n",
        "\n",
        "    # Clean up frames after video creation\n",
        "    cleanup_frames(frame_folder)\n",
        "\n",
        "\n",
        "# Generate videos for Taxi (SARSA and Q-Learning)\n",
        "print(\"\\nGenerating videos for Taxi environment...\")\n",
        "\n",
        "# Call the revised function which includes path generation and success check\n",
        "generate_video_from_learned_policy_and_path_taxi('Taxi-v3', q_table_sarsa_taxi, 'taxi_sarsa_episode.mp4')\n",
        "generate_video_from_learned_policy_and_path_taxi('Taxi-v3', q_table_qlearning_taxi, 'taxi_qlearning_episode.mp4')\n",
        "\n",
        "\n",
        "print(\"Finished attempting to generate Taxi videos.\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating videos for Taxi environment...\n",
            "Attempting to generate successful episode for Taxi-v3 for video...\n",
            "Successful episode found for Taxi-v3. Generating video...\n",
            "Video successfully created: ./taxi_sarsa_episode.mp4\n",
            "Cleaned up frame folder: frames\n",
            "Attempting to generate successful episode for Taxi-v3 for video...\n",
            "Successful episode found for Taxi-v3. Generating video...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video successfully created: ./taxi_qlearning_episode.mp4\n",
            "Cleaned up frame folder: frames\n",
            "Finished attempting to generate Taxi videos.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0e6964d",
        "outputId": "7298d657-aba2-47ea-931a-051026b48a01"
      },
      "source": [
        "# Print the learned policies for SARSA and Q-Learning in Taxi\n",
        "\n",
        "print(\"SARSA Learned Policy for Taxi:\")\n",
        "# The policy is derived by choosing the action with the maximum Q-value for each state\n",
        "sarsa_policy_taxi = np.argmax(q_table_sarsa_taxi, axis=1)\n",
        "print(sarsa_policy_taxi)\n",
        "\n",
        "print(\"\\nQ-Learning Learned Policy for Taxi:\")\n",
        "qlearning_policy_taxi = np.argmax(q_table_qlearning_taxi, axis=1)\n",
        "print(qlearning_policy_taxi)\n",
        "\n",
        "print(\"\\nInterpretation of Taxi Actions:\")\n",
        "print(\"0: Move South\")\n",
        "print(\"1: Move North\")\n",
        "print(\"2: Move East\")\n",
        "print(\"3: Move West\")\n",
        "print(\"4: Pickup passenger\")\n",
        "print(\"5: Dropoff passenger\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SARSA Learned Policy for Taxi:\n",
            "[0 4 4 4 0 0 2 0 0 0 0 0 0 0 0 0 5 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 3 3 0 0 0 0 0 2 0 2 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 2 2 0 0 0 0 0 0\n",
            " 0 0 0 2 0 0 0 0 0 3 4 0 4 4 3 3 0 3 3 0 0 0 3 5 0 0 0 1 1 1 2 0 2 2 0 0 0\n",
            " 0 2 0 0 0 1 0 0 2 0 3 1 3 0 0 0 0 3 3 0 0 0 0 0 0 3 0 0 0 0 0 0 0 2 0 1 2\n",
            " 0 0 0 0 2 0 0 0 0 2 0 0 0 3 0 0 1 0 1 2 0 0 0 0 0 0 0 0 0 2 0 0 0 3 3 0 1\n",
            " 0 1 1 3 3 0 0 0 0 3 0 0 1 3 3 0 1 1 1 2 0 2 2 0 0 0 0 2 2 2 0 1 2 0 2 0 3\n",
            " 1 1 2 0 2 2 3 3 0 3 2 2 2 0 3 2 3 2 0 3 3 3 2 0 1 2 3 3 0 3 2 2 2 0 3 2 3\n",
            " 2 0 3 3 3 2 0 2 2 3 3 0 3 0 0 0 0 3 1 3 0 0 3 3 3 1 0 1 1 3 3 0 3 3 0 0 0\n",
            " 3 1 3 3 0 1 1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1\n",
            " 1 2 0 1 2 1 2 0 1 1 3 1 0 1 1 1 3 0 1 1 1 1 0 3 1 1 1 0 1 1 1 2 0 2 2 1 1\n",
            " 0 1 0 0 0 0 1 1 1 0 0 3 3 1 1 0 1 1 1 3 0 3 0 0 3 0 1 1 1 3 0 1 1 1 1 0 1\n",
            " 1 4 4 0 4 1 1 1 0 1 1 5 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 2 0 3 1 1\n",
            " 1 0 1 1 1 1 0 3 1 1 1 0 1 1 1 1 0 1 1 1 1 0 2 1 1 1 0 1 4 4 4 0 1 1 1 5 0\n",
            " 3 3 3 1 0 1 1 3 3 0 1 3 3 3 0 1 1 3 3]\n",
            "\n",
            "Q-Learning Learned Policy for Taxi:\n",
            "[0 4 4 4 2 0 0 0 0 0 0 0 0 2 0 0 5 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 3\n",
            " 0 3 0 0 0 0 0 2 0 2 2 0 0 0 0 0 0 0 0 0 2 0 2 0 3 3 0 2 0 2 2 0 0 0 0 0 0\n",
            " 0 0 0 2 0 0 0 3 3 3 4 0 4 4 3 0 0 3 0 0 0 0 3 5 3 0 0 1 1 1 2 0 0 0 0 0 0\n",
            " 0 2 2 0 0 1 2 0 2 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 3 0 3 0 0 0 0 0 2 0 2 2\n",
            " 0 0 0 0 2 0 0 0 0 2 0 2 0 3 3 0 1 0 2 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 3 1\n",
            " 0 1 1 3 3 0 3 0 0 0 0 3 1 3 3 0 1 1 1 2 0 2 2 0 0 0 0 2 2 2 0 1 2 0 2 0 1\n",
            " 1 1 2 0 2 2 3 3 0 3 2 2 2 0 3 2 3 2 0 3 3 3 2 0 2 1 3 3 0 3 2 2 2 0 3 2 3\n",
            " 2 0 3 3 3 1 0 1 1 3 3 0 3 0 0 0 0 3 2 3 0 0 3 3 3 1 0 1 1 3 3 0 3 3 3 3 0\n",
            " 3 1 3 3 0 1 1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 2 1 1 0 1 1\n",
            " 1 2 0 1 1 1 1 0 1 1 1 1 0 1 1 1 3 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1\n",
            " 0 1 0 0 0 0 1 2 1 0 0 1 1 3 1 0 1 1 3 1 0 1 3 0 3 0 3 1 1 3 0 1 1 1 1 0 1\n",
            " 1 4 4 0 4 1 1 1 0 1 1 5 1 0 1 1 1 1 0 1 2 1 1 0 1 1 1 2 0 1 1 1 1 0 1 1 1\n",
            " 1 0 1 1 1 3 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 4 4 4 0 1 1 1 5 0\n",
            " 1 1 1 1 0 1 1 3 1 0 3 3 3 3 0 1 1 3 3]\n",
            "\n",
            "Interpretation of Taxi Actions:\n",
            "0: Move South\n",
            "1: Move North\n",
            "2: Move East\n",
            "3: Move West\n",
            "4: Pickup passenger\n",
            "5: Dropoff passenger\n"
          ]
        }
      ]
    }
  ]
}